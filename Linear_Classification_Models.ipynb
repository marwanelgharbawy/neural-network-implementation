{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62274576",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e54267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa13923",
   "metadata": {},
   "source": [
    "# 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8ff6e",
   "metadata": {},
   "source": [
    "### 1.1. Read data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f505c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the datasets (train data and test data which are pre-splitted)\n",
    "data1 = MNIST(root='MNIST_dataset', train=True, download=True)\n",
    "data2 = MNIST(root='MNIST_dataset', train=False, download=True)\n",
    "\n",
    "#concatenate the data and labels from train and test datasets\n",
    "all_images = torch.cat((data1.data, data2.data), dim=0)\n",
    "all_labels = torch.cat((data1.targets, data2.targets), dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c8c1d3",
   "metadata": {},
   "source": [
    "Now, we have 70,000 images intotal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "555a1328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 70000\n"
     ]
    }
   ],
   "source": [
    "x = all_images.numpy()\n",
    "y = all_labels.numpy()\n",
    "\n",
    "print(\"Total images:\", x.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdc43d1",
   "metadata": {},
   "source": [
    "### 1.2. Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c0cab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min pixel value: 0.0 , max pixel value: 1.0\n"
     ]
    }
   ],
   "source": [
    "x = x / 255.0  # Normalize pixel values to [0, 1] range\n",
    "\n",
    "print(\"min pixel value:\", x.min(), \", max pixel value:\", x.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f33f71",
   "metadata": {},
   "source": [
    "### 1.3. Splitting into train, validtaion and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c5a851e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set =  42000\n",
      "Validation set =  14000\n",
      "Test set =  14000\n"
     ]
    }
   ],
   "source": [
    "x_train, x_rest, y_train, y_rest = train_test_split(x, y, train_size= 0.6, random_state=42, stratify=y) # 60% train, 40% to split again into val and test\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_rest, y_rest, train_size=0.5, random_state=42, stratify=y_rest) # 40% * 50% = 20% val, 20% test\n",
    "\n",
    "print(\"Training set = \", x_train.shape[0])\n",
    "print(\"Validation set = \", x_val.shape[0])\n",
    "print(\"Test set = \", x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66350be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (42000, 28, 28)\n",
      "Flattened shape: (42000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "x_val_flat = x_val.reshape(x_val.shape[0], -1)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# Verify the new shape\n",
    "print(f\"Original shape: {x_train.shape}\")\n",
    "print(f\"Flattened shape: {x_train_flat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af943971",
   "metadata": {},
   "source": [
    "### 1.4. Pytorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453913ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change from numpy arrays to tensors\n",
    "x_train_tensor = torch.from_numpy(x_train_flat).unsqueeze(1).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).long()\n",
    "\n",
    "x_val_tensor = torch.from_numpy(x_val_flat).unsqueeze(1).float()\n",
    "y_val_tensor = torch.from_numpy(y_val).long()\n",
    "\n",
    "x_test_tensor = torch.from_numpy(x_test_flat).unsqueeze(1).float()\n",
    "y_test_tensor = torch.from_numpy(y_test).long()\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "val_dataset = torch.utils.data.TensorDataset(x_val_tensor, y_val_tensor)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders with batch size = 64 to optimize training\n",
    "train_NN_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_NN_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_NN_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13177691",
   "metadata": {},
   "source": [
    "# 2. Linear Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edcb0ae",
   "metadata": {},
   "source": [
    "## 2.1. Logistic Regression\n",
    "\n",
    "For logistic regression, it's a binary classifier, so we need to use two digits only as classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec25e45",
   "metadata": {},
   "source": [
    "### 2.1.1. Data preparation For Binary Classification\n",
    "\n",
    "Boolean masking is used to filter the dataset for two specific digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0d620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_digits(x, y, digit1, digit2):\n",
    "    filter_mask = (y == digit1) | (y == digit2)\n",
    "\n",
    "    x_filtered = x[filter_mask]\n",
    "    y_filtered = y[filter_mask]\n",
    "\n",
    "    y_filtered = np.where(y_filtered == digit1, 0, 1) # Map digit1 to 0 and digit2 to 1\n",
    "    return x_filtered, y_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad530c3",
   "metadata": {},
   "source": [
    "Filter the data for only 2 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIGIT_A = 0\n",
    "DIGIT_B = 1\n",
    "\n",
    "x_binary_train_flat, y_binary_train = filter_digits(x_train_flat, y_train, DIGIT_A, DIGIT_B)\n",
    "x_binary_val_flat, y_binary_val = filter_digits(x_val_flat, y_val, DIGIT_A, DIGIT_B)\n",
    "x_binary_test_flat, y_binary_test = filter_digits(x_test_flat, y_test, DIGIT_A, DIGIT_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a60387eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8478, 784) (8478,)\n",
      "(2826, 784) (2826,)\n",
      "(2827, 784) (2827,)\n"
     ]
    }
   ],
   "source": [
    "print(x_binary_train_flat.shape, y_binary_train.shape)\n",
    "print(x_binary_val_flat.shape, y_binary_val.shape)\n",
    "print(x_binary_test_flat.shape, y_binary_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to float tensors\n",
    "# Convert labels to columns vector\n",
    "x_train_binary_tensor = torch.from_numpy(x_binary_train_flat).float()\n",
    "y_train_binary_tensor = torch.from_numpy(y_binary_train).float().view(-1, 1)\n",
    "\n",
    "x_val_binary_tensor = torch.from_numpy(x_binary_val_flat).float()\n",
    "y_val_binary_tensor = torch.from_numpy(y_binary_val).float().view(-1, 1)\n",
    "\n",
    "x_test_binary_tensor = torch.from_numpy(x_binary_test_flat).float()\n",
    "y_test_binary_tensor = torch.from_numpy(y_binary_test).float().view(-1, 1)\n",
    "\n",
    "train_binary_dataset = torch.utils.data.TensorDataset(x_train_binary_tensor, y_train_binary_tensor)\n",
    "val_binary_dataset = torch.utils.data.TensorDataset(x_val_binary_tensor, y_val_binary_tensor)\n",
    "test_binary_dataset = torch.utils.data.TensorDataset(x_test_binary_tensor, y_test_binary_tensor)\n",
    "\n",
    "train_lr_loader = DataLoader(train_binary_dataset, batch_size=64, shuffle=True)\n",
    "val_lr_loader = DataLoader(val_binary_dataset, batch_size=64, shuffle=False)\n",
    "test_lr_loader = DataLoader(test_binary_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a1c8db",
   "metadata": {},
   "source": [
    "### 2.1.2. Defining The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb89650",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FEATURES = 784 # Number of pixels/inputs (28x28)\n",
    "OUTPUT_FEATURES = 1  # The output is either 0 or 1\n",
    "\n",
    "# Create the weights tensor of random numbers with size of (784, 1)\n",
    "weights = torch.randn(INPUT_FEATURES, OUTPUT_FEATURES, dtype=torch.float)\n",
    "\n",
    "# Create the bias tensor of zeros with size of 1 element\n",
    "bias = torch.zeros(OUTPUT_FEATURES, dtype=torch.float)\n",
    "\n",
    "# Enable gradient tracking for weights and bias\n",
    "weights.requires_grad = True\n",
    "bias.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115801e1",
   "metadata": {},
   "source": [
    "Define Sigmoid activation function and the cross entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f14cd034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + torch.exp(-z))\n",
    "\n",
    "# y_true are the labels (0 or 1) and y_pred_logits are the model outputs (logits)\n",
    "def binary_cross_entropy_loss(y_true, y_pred_logits):\n",
    "\n",
    "    p = sigmoid(y_pred_logits)\n",
    "    \n",
    "    # Prevent log(0) by adding a small value (epsilon)\n",
    "    epsilon = 1e-7\n",
    "\n",
    "    loss_per_item = - ( y_true * torch.log(p + epsilon) + (1.0 - y_true) * torch.log(1.0 - p + epsilon) )\n",
    "\n",
    "    # Return average\n",
    "    return torch.mean(loss_per_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1decc622",
   "metadata": {},
   "source": [
    "### 2.1.3 Training The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3be303b",
   "metadata": {},
   "source": [
    "Add more sections before this and change numbering if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
